{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VraNjmsRxydm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QDHhDMgZTE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2654419-854d-4390-8b67-a2558a75908a"
      },
      "source": [
        "# get yolov3 pretrained coco dataset weights\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-12 13:24:25--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights.1’\n",
            "\n",
            "yolov3.weights.1    100%[===================>] 236.52M  77.4MB/s    in 3.2s    \n",
            "\n",
            "2023-06-12 13:24:29 (73.4 MB/s) - ‘yolov3.weights.1’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YZxx3aUO5P-A"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing import image # Preprocessing the images\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Frame_by_Frame(videoFile):\n",
        "  count=0\n",
        "  cap=cv2.VideoCapture(videoFile) # capturing video\n",
        "  frameRate=cap.get(5) #framerate\n",
        "  if(not cap.isOpened()):\n",
        "    print(\"Cannot open camera\")\n",
        "    exit()\n",
        "  while True:\n",
        "    frameId = cap.get(1) # current frame number\n",
        "    ret,frame = cap.read() # capture frame by frame,it will return true if frame is read correctly,this will determine the end of the video\n",
        "    if(ret!=True):\n",
        "      break\n",
        "    if(frameId % math.floor(frameRate)==0):\n",
        "      filename=\"frame%d.jpg\" % count;count+=1\n",
        "      cv2.imwrite(filename,frame)\n",
        "  cap.release()\n",
        "  print(\"Done!\")    \n",
        "\n"
      ],
      "metadata": {
        "id": "e9mOXP5W6UdY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videoFile=\"/content/road_trafifc.mp4\"\n",
        "\n",
        "Frame_by_Frame(videoFile)\n"
      ],
      "metadata": {
        "id": "hymsK4iw7fNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2711b2d9-3ce3-47de-b529-5c158c021012"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=cv2.dnn.readNet(\"/content/yolov3.weights\",\"/content/yolov3.cfg\")\n",
        "list_of_labels=[]\n",
        "with open(\"/content/coco.names\",\"r\") as f:\n",
        "\n",
        "  list_of_labels=[line.strip() for line in f.readlines()]\n",
        "layers=n.getLayerNames()\n",
        "out_layers = [layers[i-1] for i in n.getUnconnectedOutLayers()]\n",
        "colors=np.random.uniform(0,255,size=(len(list_of_labels),3))\n"
      ],
      "metadata": {
        "id": "iKX9Gie8ANJD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Obj_detect(image_name):\n",
        "    cur_img= cv2.imread(image_name)\n",
        "    height, width, channels = cur_img.shape\n",
        "    blob = cv2.dnn.blobFromImage(cur_img, 0.00392, (416,416), (0, 0, 0), True, crop=False)\n",
        "    n.setInput(blob)\n",
        "    outs = n.forward(out_layers)\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                # Object detected\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "                # Rectangle coordinates\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "    count=0\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indexes:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(list_of_labels[class_ids[i]])\n",
        "            if(label in ['car','bus','truck','motorbike','bicycle']):\n",
        "                \n",
        "                count+=1\n",
        "            color = colors[i]\n",
        "            cv2.rectangle(cur_img, (x, y), (x + w, y + h), color, 2)\n",
        "            cv2.putText(cur_img, label, (x, y + 30), font, 3, color, 3)\n",
        "    return count"
      ],
      "metadata": {
        "id": "-L60ffxJ6QFe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_chaos=0\n",
        "no_of_frames=0\n",
        "for i in range(0,11):\n",
        "  image_n=\"/content/frame\"+str(i)+\".jpg\"\n",
        "  s= Obj_detect(image_n)\n",
        "  if(s!=0):\n",
        "    total_chaos+=s\n",
        "    no_of_frames+=1\n",
        "  "
      ],
      "metadata": {
        "id": "VWjeEHmhAunk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Total Chaos  : \",total_chaos)\n",
        "print(\"Useful no of frames : \",no_of_frames)"
      ],
      "metadata": {
        "id": "SmnSV1ndBGfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_chaos=(total_chaos/no_of_frames)\n",
        "print(\"Average Chaos : \",avg_chaos)"
      ],
      "metadata": {
        "id": "v9nGPwVBBToU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-IrqsmVsYcPM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}